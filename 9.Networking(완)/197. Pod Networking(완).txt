------------------------------------------------------------------------
[정리]
Q. [클러스터[노드[POD]] --> [클러스터[노드[POD]] 연락할 방법이 필요.

[해결책의 제시]
1. 노드 3개를 생성함. 이들 NODE 에 IP 를 부여 함.
2. 노드에 컨테이너(inPOD)가 생성되면 그들 만의 네트워크 네임스페이스가 생성 - 도커편에서 봄
3. 컨테이너별(inPod) 네트워크 네임스페이스 를 브릿지네트워크랑 연결하려함.
4. 브릿지 네트워크와 연결하기 위해 각 노드에 가상 네트워크 설치.
5. 브릿지 네트워크에 서브넷 주소 할당 && 브릿지 네트워크 서브넷에 IP 주소 할당
	>> ip addr add 10.244.1.1/24 dev v-net-0
	>> ip addr add 10.244.2.1/24 dev v-net-0
	>> ip addr add 10.244.3.1/24 dev v-net-0
6. 추가되는 컨테이너가 있으면 이 작업을 반복 하기 위해 스크립트를 작성 (net-script.sh)

7. 네임스페이스의 가상 네트워크와 브릿지 네트워크(v-net-0) 과 연결하기 위해서 pipe 또는 virtual network cable 생성
>> ip link add .... type=veth ....

8. 한쪽은 컨테이너 다른 한쪽은 브릿지 네트워크를 연결 하기위해 ip link set 명령어 사용
>> ip link set .....

9. 컨테이너 마다 존재하는 네임스페이스에도 이제 IP 를 부여 함
>> ip -n <namespace> addr add ....

10. 네임스페이스에 기본 라우터를 설정 함
>> ip -n <namespace> route ....

11. 네임스페이스와 브릿지 네트워크를 모두 연결함. (NODE내 컨테이너들 끼리 소통이 가능해짐)
>> ip -n <namespace> link set ....

12. 노드간 통신을 위해 라우트 정보를 추가한다. 10.244.2.2 를 찾는 경우 192.168.1.12 로 연결되도록
>> ip route add 10.244.2.2 via 192.168.1.12

13. 12번 작업을 모든 노드에 적용하면 노드간 통신이 가능 해진다.
-- 모든걸 연결한 거대한 게이트웨이가 생성됨.

14. 이후 새로생성되는 컨테이너에게 네트워크 합류를 자동으로 하기 위해 스크립트를 작성함.
-- CNI Container Network Inteface 에서 이과정을 함께함
-- kubelet 실행시 파라미터로 존재하는 CNI 옵션을 통해 실행 쉘 스크립트를 위치시킬수 있음.

>> kubelet
>> 	--cni-conf-dir=/etc/cni/net.d		<-- CNI 구성 파일
>> 	--cni-bin-dir=/etc/cni/bin			<-- 실행파일 위치
>> ./net-script.sh add <container> <anemsapce>
------------------------------------------------------------------------
Hello and welcome to this lecture and this lecture we discuss about pod networking in kubernetes
안녕하세요. 이번 강의에서 우리는 POD 네트워킹에 대해 알아보겠습니다.

so far we have set up several kubernetes, master and worker nodes and configured networking between them.
지금까지 우리는 여러 쿠버네티스 마스터 노드 및 워커 노드들을 설정하고 이들 사이에 네트워크를 구축 했습니다.

So they are all on a network that can reach each other.
그래서 네트워크에 있는 모든 것들은 각 서로 연결이 가능 합니다.

We also made sure the firewall and network security groups are configured correctly to allow for the kubernetes control plane components to reach each other.
우린 또한 방화벽과 네트워크 보안 그룹이 쿠버네티스 컨트롤 플레인 컴포넌트들을 허용하도록 올바르게 구성되었는지 확인했습니다.

Assume that we have also set up all the kubernetes control plane components such as the Kube API server, the ETCD servers, Kubelet, etc. and we are finally ready to deploy our applications.
우리는 또한 Kube API 서버, ETCD 서버, Kubelet 등등 모든 쿠버네티스 컨트롤 플레인 컴포넌트를 셋업 했으며 그리고 마침내 어플리케이션 배포가 준비되었다고 가정 합니다.

(address:해결하다)
But before we can do that, there is something that we must address.
하지만 이것들을 실행하기 이전에 여기에는 우리가 반듯이 해결해야 하는 것들이 있습니다.

We talked about the network that connects the nodes together, but there's also another layer of networking that is crucial to the clusters functioning, and that is the networking at the pod layer.
우리는 노드가 함께 연결 되는 네트워크에 관해 이야기 했었습니다. 하지만 이것들은 클러스터가 작동하는데 중요한 또다른 네트워크의 레이어 입니다. 그리고 노드 연결 네트워크는 POD 레이어에 있습니다.

[노드네트워크]
[POD네트워크]

Our kubernetes cluster is soon going to have a large number of pods and services running on it.
쿠버네티스 클러스터는 이제 곧 많은 수의 POD 와 서비스가 실행되게 되것입니다.

How are the pods addressed?
POD 는 어떻게 처리될까요?

How do they communicate with each other?
그들은 어떻게 서로간의 통신할까요

How do you access the services running on these pods internally from within the cluster as well as externally from outside the cluster?
클러스터로 내부는 물론 외부에서 POD 내부 에서 실행중인 서비스에 어떻게 접근 할까요?

[클러스터[노드[POD]]] -> [클러스터[노드[POD]]]
※ 다른 클러스터 에서 노드로의 통신을 의미.

These are challenges that kubernetes expects you to solve.
이것은 쿠버네티스가 당신이 해결하기를 기대하는 첼린지(과제) 입니다.

(As of today's data:오늘날짜 기준으로_
As of today, Kubernetes does not come with a built in solution for this.
현재 기준으로, 쿠버네티스는 이 문제에 대한 해답을 내놓지 않고 있습니다.

It expects you to implement a networking solution that solves these challenges.
다른 클러스터에서 노드로 접근하는 문제는 당신이 네트워크 솔루션을 구현하기를 기대합니다.

However, kubernetes have laid out clearly the requirements for pod networking.
하지만 쿠버네티스는 POD 네트워킹에 대한 요구사항을 정확히 정렬 하고 있습니다.

Let's take a look at what they are.
그것들이 무엇인지 이제 살펴보겠습니다.

------------------------------------------------------------------------
------------------------------------------------------------------------

kubernetes expects every pod to get its own unique IP address and that every pod should be able to reach every other pod within the same node using that IP address.
쿠버네티스는 모든 POD 에 각각 소유의 유니크한 IP 주소가 부여되어 있기를 기대하고 있습니다. 그리고 IP주소를 사용하여 동일 노드에서도 모든 POD 들이 각자가 소통 가능해 져야만 합니다.

(belongs to:~에 속하다)
It doesn't care what IP address that is and what range or subnet it belongs to.
이것은 어떤 IP 인지는 신경 쓰지 않습니다. 그리고 어떤 대역인지. 어떤 서브넷에 속하는지 등등 도.
(중요한건 소통이 가능해져야 한다는 것)

As long as you can implement a solution that takes care of automatically assigning IP addresses and establish connectivity between the pods in a node as well as pods on different nodes
you're good  without having to configure any networks.
IP주소를 자동으로 할당하고 노드내 포함된 POD 와 다른 노드내 포함된 POD 를 서로 연결을 구축하는 솔루션을 구축 할 수 있는 한은, 네트워크를 구성하지 않아도 됩니다.


[IP 자동 할당 && 클러스터 건너 POD들 간 연결 구축]
So how do you implement a model that solves these requirements now?
그럼 이런 요구사항을 해결 하기 위해서 어떻게 모델을 구현할까요?

There are many networking solutions available out there that does this, but we have already learned about networking concepts, routing, IP address, management namespace and CNI.
여기에는 바깥의 다양한 네트워킹 솔루션을 이용할 수 있씁니다. 하지만 우리는 네트워킹 컨셉과 라우팅, IP주소, 네임스페이스 관리와 CNI 를 이미 배웠습니다.

So let's try to use that knowledge to solve this problem by ourselves First.
그래서 우선적으로 지식을 활용하여 문제를 풀어 봅시다.

this will help in understanding how other solutions work.
다른 솔루션들은 어떻게 동작하는지의 이해가 도움이 될 것입니다.

------------------------------------------------------------------------
[다른 솔루션들이 작업 하는 내용들]
# 브릿지 네트워크를 구성
>> ip link add v-net-0 type bridge

# dev네임스페이스에 링크를 설정
>> ip link set dev v-net-0 up

# dev 네임스페이스의 브릿지에 IP 를 할당
>> ip addr add 192.168.15.5/24 dev v-net0

# veth 타입의 연결 객체를 추가
>> ip link add veth-red type beth peer name veth-reb-br

# 추가한 링크를 RED 네임스페이스에 연결
>> ip link set veth-red netns red

# RED 네임스페이스의 veth-red 에 주소를 부여.
>> ip -n red addr add 192.168.15.1 dev veth-red

# RED 네임스페이스에 veth-red 선을 연결
>> ip -n red link set veth-red up

# veth-red-br 브릿지 네트워크와 마스터 v-net-0를 서로 연결
>> ip link set veth-red-br master v-net-0

# 블루 네임스페이스의 IP 라우팅 테이블에 브릿지로 연결되는 라우팅 정보 추가
>> ip netns exec blue ip route add 192.168.1.0/24 via 192.168.15.5

# NAT : 네트워크 주소 변환, POSTROUTING : 나가는 패킷 수정
# 컴퓨터에서 나가는 모든 패킷의 IP 를 192.168.15 대력으로 변환 시킴.
>> ip tables -t nat -A POSTROUTING -s 192.168.15.0/24 -j MASQUERADE
------------------------------------------------------------------------

I know there is a bit of repetition, but I'm trying to relate the same concept and approach all the way from plane network namespace on Linux all the way to kubernetes.
저기에 약간의 반복적 요소가 있다는것을 합니다. 하지만 동일한 개념을 연결하고 접근 하려고 합니다.

솔루션 대신 직접 구성하기.
------------------------------------------------------------------------
So we have a three node cluster.
그러기 위해 우리는 3개의 노드 클러스터를 가져왔습니다.

It doesn't matter which one is master or worker, they all run pods either for management or workload purposes.
누가 마스터고 워커인지는 중요하지 않습니다. 이들 모두 관리 또는 워크 로드용으로 포드를 실행합니다.

As far as networking is concerned, we're going to consider all of them as the same.
네트워크에 관한한, 우리는 이 노드들을 모두 같은것으로 간주 할 것입니다.

So first, let's plan what we are going to do.
가장 먼저, 우리가 무엇을 할지 계획을 세웁시다.

The nodes are pod of an external network and has IP addresses in the 192.168.1 series.
여기 이 노드들은 외부 네트워크의 POD 입니다. 그리고 192.168.1 대력의 IP 주소를 가집니다.

Node one is assigned 11, node two is 12 and node three is 13
노드 1은 11 은 2는 12를 3은 13의 IP 를 할당 받았습니다.

[Node1:192.168.1.11]
[Node2:192.168.1.12]
[Node3:192.168.1.13]

Next step, when containers are created, kubernetes creates network namespace for them 
다음 단계로, 컨테이너가 생성 될때 마다, 쿠버네티스는 네트워크 네임스페이스를 생성합니다. 

to enable communication between them we attach these names to a network, but what network?
우리는 이 네트워크 네임스페이스와 소통 하기 위해서 네트워크 네임스페이스를 네트워크에 연결 합니다.
하지만 어떤 네트워크 인가요?

We have learned about bridge networks that can be created within nodes to attach namesspaces.
우리는 네임스페이스에 연결하기 위한 노드안에서 생성될 수 있는 브릿지 네트워크에 대해 배웠습니다.

So we create a virtual network on each node.
그래서 우리는 가상의 네트워크를 각각의 노드에 생성 합니다.

And then bring them up, it's time to assign an IP address to the Bridge interfaces or networks.
그런다음 가상 네트워크를 불러와서 브릿지 인터페이스 또는 네트워크에 IP 주소를 할당할 차례입니다.

But what IP address?
하지만 무슨 IP 주소 일까요?

We decide that each bridge network will be on its own subnet 
우리는 각 브릿지 네트워크가 그들 소유의 서브넷을 가질 수 있도록 결정합니다. 

(say:예)
choose any private address range say, 10.244.1.0, 10.244.2.0 and 10.244.3.0
개인주소범위을 선택합니다. 

Next we set the IP address for the bridge interface.
다음으로 브릿지 인터페이스에 IP 주소를 설정 합니다.

>> ip addr add 10.244.1.1/24 dev v-net-0
>> ip addr add 10.244.2.1/24 dev v-net-0
>> ip addr add 10.244.3.1/24 dev v-net-0

So we have built our base.
이렇게 우리는 우리의 베이스를 구축 했습니다.

The remaining steps are to be performed for each container and every time a new container is created.
나머지 단계는 각각 컨테이너 마다 그리고 새 컨테이너가 생성될 때 마다 수행 되어야 합니다.

So we write a script for it.
그래서 이작업을 위해 스크립트를 작성 합니다.

Now, you don't have to know any kind of complicated scripting.
이제 어떤 종류의 복잡한 스크립팅도 알 필요가 없습니다.

It's just a file that has all commands we will be using 
이것은 우리가 사용할 모든 명령이 담긴 파일입니다.

and we can run this multiple times for each container going forward 
그리고 우리는 컨테이너가 새로 생길때 마다 반복적으로 실행 가능 합니다.

to attach a container to the network. 
컨테이너를 네트워크에 연결 시키기 위해서는

We need a pipe or virtual network cable.
우리는 파이트 또는 가상의 네트워크 케이블이 필요합니다.

We create that using the IP link, add command, 
우린 이것을 ip link add 명령으로 생성합니다.

>> ip link add ......

don't focus on the options as they are similar to what we saw in our previous lectures.
옵션에 대해서는 신경 쓰지 마세요. 이 옵션은 이전 강의에서 본적과 유사 하므로.

Assume that they are very depending on the inputs.
이것들은 입력값에 대해 매우 의존적이라고 가정 합시다.

We then attach one end to the container and another end to the bridge using the IP links that command.
우린 하나의 종단을 컨테이너에 연결 합니다. 그리고 나머지 끝을 브릿지에 연결 합니다. ip link 명령으로.

We then assign IP address using the IP ADDR command and add a route to the default gateway.
그런 다음 우리는 IP 주소를 할당 합니다. ip addr 명령을 사용하여, 그리고 기본 게이트 웨이를 향하는 라우터를 추가합니다.

But what IP do we add?
하지만 어떤 IP 를 추가하나요?

We either manage that ourselves or stored that information in some kind of database.
우리는 이것을 스스로 관리하거나 데이터 베이스 같은 것에 저장하여 관리하고 있습니다.

For now, we will assume it is 10.244.2, which is a free IP in the subnet.
지금은, 이 IP 를 10.244.2 로 가정 합니다. 이것은 서브넷에서 남는 IP 입니다.

We discuss about IP address management in detail in one of the upcoming lectures.
우리는 IP 주소 관리에 대해서 다가오는 강의중 하나에서 다룰 것입니다.

Finally, we bring up the interface.
마지막으로 인터페이스를 가져 옵니다.

We don't run the same script this time from the second container with its information and gets the container connected to the network, 
우리는 이번 두번째 컨테이너에서는 동일한 스크립트를 사용할 수 없습니다. 그리고 컨테이너를 네트워크에 연결 할 수도 없습니다.

the two containers can now communicate with each other.
두개의 컨테이너를 지금 서로 통신을 할 수 있습니다.

We copy the script to the other nodes and run the script on them to assign IP address and connect those containers to their own internal networks.
우리는 이 스크립트를 복사하여 다른 노드에게 건냅니다. 그리고 스크립트를 그 노드에서 실행합니다. IP 를 할당받고 컨테이너를 그들 내부의 네트워크에 연결 하기 위해서요.

So we have solved the first pod of the challenge.
그래서 우리는 첫번째 POD 의 문제를 해결 했습니다.
------------------------------------------------------------------------
The pods all get their own unique IP address and are able to communicate with each other on their own Nodes
POD들은 모두 그들만의 유니크한 IP 주소를 가졌습니다. 그리고 모두 그들의 NODE 에서 다른 노드로의 커뮤니케이션이 가능해 졌습니다.

the next part is to enable them to reach other pods on other nodes.
다음 부분은 그들이 다른 노드의 POD 들에 닿을 수 있게 되는 것 입니다.

So, for example, the pod at 10.244.1.2 on node1 wants to ping for 10.244.2.2 on node2.
예를 들어 Node에1(10.144.1.2) 에 있는 POD 는 Node2(10.244.2.2) 로 Ping 을 보내길 원 합니다.

(As of now:지금과 같은)
As of now, the first has no idea where the addresses 10.244.2.2 is because it is on a different network than its own.
지금과 같이 첫번째 노드가 10.244.2.2 가 어디인지 모르는 경우는 노드2가 노드1와 다른 네트워크에 있기 때문입니다.

So it routes to Node1's IP as it is set to be the default gateway.
이것은 기본 게이트웨이로 설정되어 있으므로, Node1 의 IP 로 라우팅 됩니다.

node1 doesn't know either, since 10.244.2.2 is a private network on node2.
Node1 은 서로를 모릅니다. 10.244.2.2 는 Node2 의 개인 네트워크이기 때문입니다.

add a route to node1 routing table to road traffic to 10.244.2.2 second nodes IP at 192.168.1.12
Node1 의 라우팅 테이블에 경로를 추가합니다. 10.244.2.2 로 향하는 트래픽을 192.168.1.12로 보내는 경로로.

>> ip route add 10.244.2.2 via 192.168.1.12

Once the route is added, the blue pod is able to ping across.
라우트가 추가되면 이제 블루 POD 가 노드를 건너 핑을 보낼수 있습니다.

Similarly, we configure route on all host to all the other hosts with information regarding the respective networks within them.
동일하게 우리는 네트워크 정보를 이용하여 모든 호스트에서 다른 모든 호스트로의 라우트를 구성 할 수 있습니다.

Now this works fine in this simple setup, but this will require a lot more configuration, as in when your underlying network architecture gets complicated.
지금 이 간단한 설정으로 작업은 완료되었습니다. 하지만 여기에는 네트워크 아키텍처가 점점 복잡해진것처럼 더 많은 설정을 필요로 할 것 입니다.

instead of having to configure a route on each server.
각 서버에 라우터를 집어 너는 방법 대신에.

A better solution is to do that on a router 
좀더 나은 방법은 라우터에 이걸 하는 것입니다.

if you have one in your network and point all hosts to use that as the default gateway.
만약 당신이 당신의 네트워크에 하나가 있고 모든 호스트를 가리킬수 있는 기본 게이트웨이처럼 사용할 수 있는 것이 있다면.

That way you can easily manage wrote to all networks in the routing table on the router.
이 방법으로 라우터에 라우팅 테이블의 모든 네트워크를 손쉽게 관리할 수 있습니다.


[10.244.0.0./16 모든걸 묶은 광대역 라우터]

With that, the individual virtual networks we created with the address 10.244 1.0/24 on each node now form a single large network with the address 10.244.0.0/16.
이걸 통해 각 노드에 올려진 10.244.1.0/24의 IP 개인 가상 네트워크를 이제 10.244.0.0/16의 싱글 대형 네트워크로 만들어 낼 수 있습니다.

It's time to tie everything together.
모든것들을 한번에 하나로 묶을 시간입니다.

We performed a number of manual steps to get the environment ready with the bridge networks and routing tables.
우리는 환경을 준비하기 위해 브릿지 네트워크와 라우팅 테이블과 함께 몇몇 메뉴얼 작업을 수행 했습니다.

We then wrote a script that can be run for each container that performs the necessary steps required to connect each container to the network.
그런 다음 우리는 각 컨테이너가 네트워크에 접속 할수 있도록 요청된 필수 작업을 수행하는 스크립트를 작성 했습니다.

And we executed the script manually.
그리고 우리는 이 스크립트를 수동으로 실행했습니다.

Of course, we don't want to do that, as in large environments where thousands of pods are created every minute.
당연하지만 우리는 수천개의 POD 가 매분 생성되는 거대한 환경에서 실행하기를 원치 않습니다.

So how do we run the script automatically when a pod is created on kubernetes?
그럼 어떻게 쿠버네티스에 하나의 POD 가 생성되면 자동으로 스크립트를 실행 시킬 수 있을까요?
----------------------------------------------------------------------

[CNI]
COntainer Network Interface

That's where CNI comes in.
여기가 CNI 가 등장 하는 곳입니다.

Acting as the middleman.
중계자 처럼 행동 합니다.

CNI tells kubernetes that this is how you should call a script as soon as you create a container.
CNI 는 컨테이너를 생성하자마자 스크립트를 호출 해야하는 방식 쿠버네티스에세 알려줍니다. 

And CNI tells us this is how your script should look like.
그리고 CNI 는 우리에게 스크립트가 어떻게 생겼는지 알려줍니다.

So we need to modify the script a little bit to meet CNI standards.
그래서 우리는 CNI 표준에 맞게 스크립트를 수정 해야 합니다.

It should have an add section that will take care of adding a container to the network and a delete section that will take care of deleting container interfaces from the network and freeing the IP address, etc..
이것은 네트워크에 컨테이너를 추가하는걸 담당하는 추가 섹션이 있어야 합니다. 그리고 네트워크에 컨테이너 인터페이스 삭제를 관장하는 딜리트 섹션, 그리고 IP를 반납하는 등등.

So our script is ready.
우리의 스크립트가 준비 되었습니다.

The kubelet on each node is responsible for creating containers 
각 노드의 큐블렛은 컨테이너 생성을 담당합니다.

whenever the container is created The Kubelet looks at the CNI configuration passed as a command line argument when it was run and identifies our scripts name.
컨테이너에 큐블렛이 생성될때마다, Kubelet 은 실행될때 명령줄 인수로 전달된 CNI 구성을 살펴보고 스크립트 이름을 식별합니다.

>> kubelet
>> 	--cni-conf-dir=/etc/cni/net.d		<-- CNI 구성 파일
>> 	--cni-bin-dir=/etc/cni/bin			<-- 실행파일 위치
>> ./net-script.sh add <container> <anemsapce>
It then looks in the /etc/cni/bin directory, defined our script and then executes the script with the ADD command and the name and namespace ID of the container.

>> ./net-script.sh add <container> <anemsapce>
------------------------------------------------------------------------
(rest:나머지)
And then our script takes care of the rest.
그런 다음 우리의 스크립트가 나머지를 처리합니다.

We will look at how and where the CNI is configured on kubernetes
우리는 어떻게 그리고 어디에서 이 CNI 가 설정되는지 를 확인하였습니다.

(along with:~함께)
in the next lecture, along with practice tests.
우리는 다음 강의에서 연습 문제를 함께 하겠습니다.

For now, the set from the pod networking concepts lecture.
지금까지는 POD 네트워크 컨셉 강의였습니다.

Hopefully that should give you enough knowledge on inspecting networking within pods in a kubernetes cluster.

We will see how other solutions do the same thing that we did in the upcoming lectures.